using System;
using Microsoft.VisualStudio.TestTools.UnitTesting;
using SharpLearning.InputOutput.Csv;
using System.IO;
using SharpLearning.GradientBoost.Test.Properties;
using SharpLearning.Metrics.Classification;
using SharpLearning.GradientBoost.Learners;
using SharpLearning.Containers;
using System.Collections.Generic;
using System.Diagnostics;
using System.Linq;
using SharpLearning.GradientBoost.Models;

namespace SharpLearning.GradientBoost.Test.Models
{
    [TestClass]
    public class ClassificationGradientBoostModelTest
    {
        [TestMethod]
        public void ClassificationGradientBoostModel_Predict_Single()
        {
            var parser = new CsvParser(() => new StringReader(Resources.AptitudeData));
            var observations = parser.EnumerateRows(v => v != "Pass").ToF64Matrix();
            var targets = parser.EnumerateRows("Pass").ToF64Vector();
            var rows = targets.Length;

            var learner = new ClassificationMultinomialDevianceGradientBoostLearner();
            var sut = learner.Learn(observations, targets);

            var predictions = new double[rows];
            for (int i = 0; i < rows; i++)
            {
                predictions[i] = sut.Predict(observations.GetRow(i));
            }

            var evaluator = new TotalErrorClassificationMetric<double>();
            var error = evaluator.Error(targets, predictions);

            Assert.AreEqual(0.038461538461538464, error, 0.0000001);
        }

        [TestMethod]
        public void ClassificationGradientBoostModel_Predict_Multiple()
        {
            var parser = new CsvParser(() => new StringReader(Resources.AptitudeData));
            var observations = parser.EnumerateRows(v => v != "Pass").ToF64Matrix();
            var targets = parser.EnumerateRows("Pass").ToF64Vector();
            var rows = targets.Length;

            var learner = new ClassificationMultinomialDevianceGradientBoostLearner();
            var sut = learner.Learn(observations, targets);

            var predictions = sut.Predict(observations);

            var evaluator = new TotalErrorClassificationMetric<double>();
            var error = evaluator.Error(targets, predictions);

            Assert.AreEqual(0.038461538461538464, error, 0.0000001);
        }

        [TestMethod]
        public void ClassificationGradientBoostModel_PredictProbability_Single()
        {
            var parser = new CsvParser(() => new StringReader(Resources.AptitudeData));
            var observations = parser.EnumerateRows(v => v != "Pass").ToF64Matrix();
            var targets = parser.EnumerateRows("Pass").ToF64Vector();
            var rows = targets.Length;

            var learner = new ClassificationMultinomialDevianceGradientBoostLearner();
            var sut = learner.Learn(observations, targets);

            var actual = new ProbabilityPrediction[rows];
            for (int i = 0; i < rows; i++)
            {
                actual[i] = sut.PredictProbability(observations.GetRow(i));
            }

            var evaluator = new TotalErrorClassificationMetric<double>();
            var error = evaluator.Error(targets, actual.Select(p => p.Prediction).ToArray());

            Assert.AreEqual(0.038461538461538464, error, 0.0000001);

            var expected = new ProbabilityPrediction[] { new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.913457002399443 }, { 1, 0.0865429976005569 }, }), new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.560546939908104 }, { 1, 0.439453060091896 }, }), new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.850920111318499 }, { 1, 0.149079888681501 }, }), new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.920017138224685 }, { 1, 0.079982861775315 }, }), new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.560546939908104 }, { 1, 0.439453060091896 }, }), new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.908701638544693 }, { 1, 0.0912983614553073 }, }), new ProbabilityPrediction(1, new Dictionary<double, double> { { 0, 0.333766307509478 }, { 1, 0.666233692490522 }, }), new ProbabilityPrediction(1, new Dictionary<double, double> { { 0, 0.310654345298818 }, { 1, 0.689345654701182 }, }), new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.868389272463763 }, { 1, 0.131610727536237 }, }), new ProbabilityPrediction(1, new Dictionary<double, double> { { 0, 0.30500824511542 }, { 1, 0.69499175488458 }, }), new ProbabilityPrediction(1, new Dictionary<double, double> { { 0, 0.107219943051265 }, { 1, 0.892780056948735 }, }), new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.850920111318499 }, { 1, 0.149079888681501 }, }), new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.762662663274623 }, { 1, 0.237337336725377 }, }), new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.932188426982944 }, { 1, 0.0678115730170562 }, }), new ProbabilityPrediction(1, new Dictionary<double, double> { { 0, 0.184743826917209 }, { 1, 0.815256173082791 }, }), new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.911976727437457 }, { 1, 0.0880232725625425 }, }), new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.908701638544693 }, { 1, 0.0912983614553073 }, }), new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.750835408508563 }, { 1, 0.249164591491437 }, }), new ProbabilityPrediction(1, new Dictionary<double, double> { { 0, 0.30500824511542 }, { 1, 0.69499175488458 }, }), new ProbabilityPrediction(1, new Dictionary<double, double> { { 0, 0.124394439925571 }, { 1, 0.875605560074429 }, }), new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.868389272463763 }, { 1, 0.131610727536237 }, }), new ProbabilityPrediction(1, new Dictionary<double, double> { { 0, 0.30500824511542 }, { 1, 0.69499175488458 }, }), new ProbabilityPrediction(1, new Dictionary<double, double> { { 0, 0.302049422791982 }, { 1, 0.697950577208018 }, }), new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.911976727437457 }, { 1, 0.0880232725625425 }, }), new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.908701638544693 }, { 1, 0.0912983614553073 }, }), new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.868389272463763 }, { 1, 0.131610727536237 }, }), };
            CollectionAssert.AreEqual(expected, actual);
        }

        [TestMethod]
        public void ClassificationGradientBoostModel_PredictProbability_Multiple()
        {
            var parser = new CsvParser(() => new StringReader(Resources.AptitudeData));
            var observations = parser.EnumerateRows(v => v != "Pass").ToF64Matrix();
            var targets = parser.EnumerateRows("Pass").ToF64Vector();
            var rows = targets.Length;

            var learner = new ClassificationMultinomialDevianceGradientBoostLearner();
            var sut = learner.Learn(observations, targets);

            var actual = sut.PredictProbability(observations);
            var evaluator = new TotalErrorClassificationMetric<double>();
            var error = evaluator.Error(targets, actual.Select(p => p.Prediction).ToArray());

            Assert.AreEqual(0.038461538461538464, error, 0.0000001);

            var expected = new ProbabilityPrediction[] { new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.913457002399443 }, { 1, 0.0865429976005569 }, }), new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.560546939908104 }, { 1, 0.439453060091896 }, }), new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.850920111318499 }, { 1, 0.149079888681501 }, }), new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.920017138224685 }, { 1, 0.079982861775315 }, }), new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.560546939908104 }, { 1, 0.439453060091896 }, }), new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.908701638544693 }, { 1, 0.0912983614553073 }, }), new ProbabilityPrediction(1, new Dictionary<double, double> { { 0, 0.333766307509478 }, { 1, 0.666233692490522 }, }), new ProbabilityPrediction(1, new Dictionary<double, double> { { 0, 0.310654345298818 }, { 1, 0.689345654701182 }, }), new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.868389272463763 }, { 1, 0.131610727536237 }, }), new ProbabilityPrediction(1, new Dictionary<double, double> { { 0, 0.30500824511542 }, { 1, 0.69499175488458 }, }), new ProbabilityPrediction(1, new Dictionary<double, double> { { 0, 0.107219943051265 }, { 1, 0.892780056948735 }, }), new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.850920111318499 }, { 1, 0.149079888681501 }, }), new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.762662663274623 }, { 1, 0.237337336725377 }, }), new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.932188426982944 }, { 1, 0.0678115730170562 }, }), new ProbabilityPrediction(1, new Dictionary<double, double> { { 0, 0.184743826917209 }, { 1, 0.815256173082791 }, }), new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.911976727437457 }, { 1, 0.0880232725625425 }, }), new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.908701638544693 }, { 1, 0.0912983614553073 }, }), new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.750835408508563 }, { 1, 0.249164591491437 }, }), new ProbabilityPrediction(1, new Dictionary<double, double> { { 0, 0.30500824511542 }, { 1, 0.69499175488458 }, }), new ProbabilityPrediction(1, new Dictionary<double, double> { { 0, 0.124394439925571 }, { 1, 0.875605560074429 }, }), new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.868389272463763 }, { 1, 0.131610727536237 }, }), new ProbabilityPrediction(1, new Dictionary<double, double> { { 0, 0.30500824511542 }, { 1, 0.69499175488458 }, }), new ProbabilityPrediction(1, new Dictionary<double, double> { { 0, 0.302049422791982 }, { 1, 0.697950577208018 }, }), new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.911976727437457 }, { 1, 0.0880232725625425 }, }), new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.908701638544693 }, { 1, 0.0912983614553073 }, }), new ProbabilityPrediction(0, new Dictionary<double, double> { { 0, 0.868389272463763 }, { 1, 0.131610727536237 }, }), };
            CollectionAssert.AreEqual(expected, actual);
        }

        [TestMethod]
        public void ClassificationGradientBoostModel_GetVariableImportance()
        {
            var parser = new CsvParser(() => new StringReader(Resources.AptitudeData));
            var observations = parser.EnumerateRows(v => v != "Pass").ToF64Matrix();
            var targets = parser.EnumerateRows("Pass").ToF64Vector();
            var featureNameToIndex = new Dictionary<string, int> { { "AptitudeTestScore", 0 }, 
                { "PreviousExperience_month", 1 } };

            var learner = new ClassificationMultinomialDevianceGradientBoostLearner();
            var sut = learner.Learn(observations, targets);

            var actual = sut.GetVariableImportance(featureNameToIndex);
            var expected = new Dictionary<string, double> { { "PreviousExperience_month", 100.0 }, 
                { "AptitudeTestScore", 6.40056573424425 } };

            Assert.AreEqual(expected.Count, actual.Count);
            var zip = expected.Zip(actual, (e, a) => new { Expected = e, Actual = a });

            foreach (var item in zip)
            {
                Assert.AreEqual(item.Expected.Key, item.Actual.Key);
                Assert.AreEqual(item.Expected.Value, item.Actual.Value, 0.000001);
            }
        }

        [TestMethod]
        public void ClassificationGradientBoostModel_GetRawVariableImportance()
        {
            var parser = new CsvParser(() => new StringReader(Resources.AptitudeData));
            var observations = parser.EnumerateRows(v => v != "Pass").ToF64Matrix();
            var targets = parser.EnumerateRows("Pass").ToF64Vector();

            var learner = new ClassificationMultinomialDevianceGradientBoostLearner();
            var sut = learner.Learn(observations, targets);

            var actual = sut.GetRawVariableImportance();
            var expected = new double[] { 0.41075839873880021, 6.41753269622971 };

            Assert.AreEqual(expected.Length, actual.Length);

            for (int i = 0; i < expected.Length; i++)
            {
                Assert.AreEqual(expected[i], actual[i], 0.000001);
            }
        }

        [TestMethod]
        public void ClassificationGradientBoostModel_Save()
        {
            var parser = new CsvParser(() => new StringReader(Resources.AptitudeData));
            var observations = parser.EnumerateRows(v => v != "Pass").ToF64Matrix();
            var targets = parser.EnumerateRows("Pass").ToF64Vector();

            var learner = new ClassificationMultinomialDevianceGradientBoostLearner(2);
            var sut = learner.Learn(observations, targets);

            var writer = new StringWriter();
            sut.Save(() => writer);

            Assert.AreEqual(ClassificationGradientBoostModelString, writer.ToString());
        }

        [TestMethod]
        public void ClassificationGradientBoostModel_Load()
        {
            var parser = new CsvParser(() => new StringReader(Resources.AptitudeData));
            var observations = parser.EnumerateRows(v => v != "Pass").ToF64Matrix();
            var targets = parser.EnumerateRows("Pass").ToF64Vector();

            var reader = new StringReader(ClassificationGradientBoostModelString);
            var sut = ClassificationGradientBoostModel.Load(() => reader);

            var predictions = sut.Predict(observations);

            var evaluator = new TotalErrorClassificationMetric<double>();
            var error = evaluator.Error(targets, predictions);

            Assert.AreEqual(0.19230769230769232, error, 0.0000001);
        }

        void Write(ProbabilityPrediction[] predictions)
        {
            var value = "new ProbabilityPrediction[] {";
            foreach (var item in predictions)
            {
                value += "new ProbabilityPrediction(" + item.Prediction + ", new Dictionary<double, double> {";
                foreach (var prob in item.Probabilities)
                {
                    value += "{" + prob.Key + ", " + prob.Value + "}, ";
                }
                value += "}),";
            }
            value += "};";

            Trace.WriteLine(value);
        }

        readonly string ClassificationGradientBoostModelString =
            "<?xml version=\"1.0\" encoding=\"utf-16\"?>\r\n<ClassificationGradientBoostModel xmlns:i=\"http://www.w3.org/2001/XMLSchema-instance\" z:Id=\"1\" xmlns:z=\"http://schemas.microsoft.com/2003/10/Serialization/\" xmlns=\"http://schemas.datacontract.org/2004/07/SharpLearning.GradientBoost.Models\">\r\n  <m_learningRate>0.1</m_learningRate>\r\n  <m_models xmlns:d2p1=\"http://schemas.datacontract.org/2004/07/SharpLearning.DecisionTrees.Models\" z:Id=\"2\" z:Size=\"2\">\r\n    <d2p1:ArrayOfRegressionDecisionTreeModel z:Id=\"3\" z:Size=\"2\">\r\n      <d2p1:RegressionDecisionTreeModel z:Id=\"4\">\r\n        <d2p1:Tree xmlns:d5p1=\"http://schemas.datacontract.org/2004/07/SharpLearning.DecisionTrees.Nodes\" z:Id=\"5\">\r\n          <d5p1:Nodes z:Id=\"6\" z:Size=\"7\">\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>-1</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>2</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>0</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>1</d5p1:RightIndex>\r\n              <d5p1:Value>20</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>-1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>0</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>-1</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>1</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>-1</d5p1:RightIndex>\r\n              <d5p1:Value>-1.1297842681228167</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>-1</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>4</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>2</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>3</d5p1:RightIndex>\r\n              <d5p1:Value>2.5</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>-1</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>6</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>3</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>5</d5p1:RightIndex>\r\n              <d5p1:Value>13.5</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>-1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>1</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>-1</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>4</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>-1</d5p1:RightIndex>\r\n              <d5p1:Value>-1.1297842681228167</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>-1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>2</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>-1</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>5</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>-1</d5p1:RightIndex>\r\n              <d5p1:Value>-0.11641146960692048</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>-1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>3</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>-1</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>6</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>-1</d5p1:RightIndex>\r\n              <d5p1:Value>0.62672858263806974</d5p1:Value>\r\n            </d5p1:Node>\r\n          </d5p1:Nodes>\r\n          <d5p1:Probabilities xmlns:d6p1=\"http://schemas.microsoft.com/2003/10/Serialization/Arrays\" z:Id=\"7\" z:Size=\"4\">\r\n            <d6p1:ArrayOfdouble z:Id=\"8\" z:Size=\"0\" />\r\n            <d6p1:ArrayOfdouble z:Id=\"9\" z:Size=\"0\" />\r\n            <d6p1:ArrayOfdouble z:Id=\"10\" z:Size=\"0\" />\r\n            <d6p1:ArrayOfdouble z:Id=\"11\" z:Size=\"0\" />\r\n          </d5p1:Probabilities>\r\n          <d5p1:TargetNames xmlns:d6p1=\"http://schemas.microsoft.com/2003/10/Serialization/Arrays\" z:Id=\"12\" z:Size=\"2\">\r\n            <d6p1:double>0.44256236708869268</d6p1:double>\r\n            <d6p1:double>-0.55743763291130732</d6p1:double>\r\n          </d5p1:TargetNames>\r\n          <d5p1:VariableImportance xmlns:d6p1=\"http://schemas.microsoft.com/2003/10/Serialization/Arrays\" z:Id=\"13\" z:Size=\"2\">\r\n            <d6p1:double>0</d6p1:double>\r\n            <d6p1:double>2.724458874458878</d6p1:double>\r\n          </d5p1:VariableImportance>\r\n        </d2p1:Tree>\r\n        <d2p1:m_variableImportance xmlns:d5p1=\"http://schemas.microsoft.com/2003/10/Serialization/Arrays\" z:Ref=\"13\" i:nil=\"true\" />\r\n      </d2p1:RegressionDecisionTreeModel>\r\n      <d2p1:RegressionDecisionTreeModel z:Id=\"14\">\r\n        <d2p1:Tree xmlns:d5p1=\"http://schemas.datacontract.org/2004/07/SharpLearning.DecisionTrees.Nodes\" z:Id=\"15\">\r\n          <d5p1:Nodes z:Id=\"16\" z:Size=\"13\">\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>-1</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>2</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>0</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>1</d5p1:RightIndex>\r\n              <d5p1:Value>15.5</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>-1</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>4</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>1</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>3</d5p1:RightIndex>\r\n              <d5p1:Value>17</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>-1</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>6</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>2</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>5</d5p1:RightIndex>\r\n              <d5p1:Value>4.5</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>0</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>-1</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>8</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>3</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>7</d5p1:RightIndex>\r\n              <d5p1:Value>2.5</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>-1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>0</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>-1</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>4</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>-1</d5p1:RightIndex>\r\n              <d5p1:Value>-1.2548560961458313</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>0</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>-1</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>10</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>5</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>9</d5p1:RightIndex>\r\n              <d5p1:Value>1.5</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>0</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>-1</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>12</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>6</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>11</d5p1:RightIndex>\r\n              <d5p1:Value>4</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>-1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>1</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>-1</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>7</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>-1</d5p1:RightIndex>\r\n              <d5p1:Value>0.11162483573977521</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>-1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>2</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>-1</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>8</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>-1</d5p1:RightIndex>\r\n              <d5p1:Value>-0.79668889007991672</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>-1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>3</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>-1</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>9</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>-1</d5p1:RightIndex>\r\n              <d5p1:Value>0.6870320175152127</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>-1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>4</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>-1</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>10</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>-1</d5p1:RightIndex>\r\n              <d5p1:Value>0.22052362021603239</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>-1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>5</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>-1</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>11</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>-1</d5p1:RightIndex>\r\n              <d5p1:Value>-0.77972867245236321</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>-1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>6</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>-1</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>12</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>-1</d5p1:RightIndex>\r\n              <d5p1:Value>0.68048832179193319</d5p1:Value>\r\n            </d5p1:Node>\r\n          </d5p1:Nodes>\r\n          <d5p1:Probabilities xmlns:d6p1=\"http://schemas.microsoft.com/2003/10/Serialization/Arrays\" z:Id=\"17\" z:Size=\"7\">\r\n            <d6p1:ArrayOfdouble z:Id=\"18\" z:Size=\"0\" />\r\n            <d6p1:ArrayOfdouble z:Id=\"19\" z:Size=\"0\" />\r\n            <d6p1:ArrayOfdouble z:Id=\"20\" z:Size=\"0\" />\r\n            <d6p1:ArrayOfdouble z:Id=\"21\" z:Size=\"0\" />\r\n            <d6p1:ArrayOfdouble z:Id=\"22\" z:Size=\"0\" />\r\n            <d6p1:ArrayOfdouble z:Id=\"23\" z:Size=\"0\" />\r\n            <d6p1:ArrayOfdouble z:Id=\"24\" z:Size=\"0\" />\r\n          </d5p1:Probabilities>\r\n          <d5p1:TargetNames xmlns:d6p1=\"http://schemas.microsoft.com/2003/10/Serialization/Arrays\" z:Id=\"25\" z:Size=\"11\">\r\n            <d6p1:double>0.24891919552140385</d6p1:double>\r\n            <d6p1:double>0.5506150806156872</d6p1:double>\r\n            <d6p1:double>0.29818027433282523</d6p1:double>\r\n            <d6p1:double>-0.4493849193843128</d6p1:double>\r\n            <d6p1:double>-0.60154793722108735</d6p1:double>\r\n            <d6p1:double>-0.70181972566717477</d6p1:double>\r\n            <d6p1:double>-0.19492657744224937</d6p1:double>\r\n            <d6p1:double>-0.24663980739104113</d6p1:double>\r\n            <d6p1:double>0.39845206277891265</d6p1:double>\r\n            <d6p1:double>0.26523353305557451</d6p1:double>\r\n            <d6p1:double>-0.42397078212693362</d6p1:double>\r\n          </d5p1:TargetNames>\r\n          <d5p1:VariableImportance xmlns:d6p1=\"http://schemas.microsoft.com/2003/10/Serialization/Arrays\" z:Id=\"26\" z:Size=\"2\">\r\n            <d6p1:double>0.14650665968579257</d6p1:double>\r\n            <d6p1:double>0.5998664169911978</d6p1:double>\r\n          </d5p1:VariableImportance>\r\n        </d2p1:Tree>\r\n        <d2p1:m_variableImportance xmlns:d5p1=\"http://schemas.microsoft.com/2003/10/Serialization/Arrays\" z:Ref=\"26\" i:nil=\"true\" />\r\n      </d2p1:RegressionDecisionTreeModel>\r\n    </d2p1:ArrayOfRegressionDecisionTreeModel>\r\n    <d2p1:ArrayOfRegressionDecisionTreeModel z:Id=\"27\" z:Size=\"2\">\r\n      <d2p1:RegressionDecisionTreeModel z:Id=\"28\">\r\n        <d2p1:Tree xmlns:d5p1=\"http://schemas.datacontract.org/2004/07/SharpLearning.DecisionTrees.Nodes\" z:Id=\"29\">\r\n          <d5p1:Nodes z:Id=\"30\" z:Size=\"13\">\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>-1</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>2</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>0</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>1</d5p1:RightIndex>\r\n              <d5p1:Value>13.5</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>-1</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>4</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>1</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>3</d5p1:RightIndex>\r\n              <d5p1:Value>20</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>-1</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>6</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>2</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>5</d5p1:RightIndex>\r\n              <d5p1:Value>4.5</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>-1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>0</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>-1</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>3</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>-1</d5p1:RightIndex>\r\n              <d5p1:Value>0.80240373790519981</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>0</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>-1</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>8</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>4</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>7</d5p1:RightIndex>\r\n              <d5p1:Value>2.5</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>-1</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>10</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>5</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>9</d5p1:RightIndex>\r\n              <d5p1:Value>9.5</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>0</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>-1</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>12</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>6</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>11</d5p1:RightIndex>\r\n              <d5p1:Value>4</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>-1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>1</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>-1</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>7</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>-1</d5p1:RightIndex>\r\n              <d5p1:Value>-0.24614269201187752</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>-1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>2</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>-1</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>8</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>-1</d5p1:RightIndex>\r\n              <d5p1:Value>0.42586451486861743</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>-1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>3</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>-1</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>9</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>-1</d5p1:RightIndex>\r\n              <d5p1:Value>-0.45688748580263833</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>-1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>4</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>-1</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>10</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>-1</d5p1:RightIndex>\r\n              <d5p1:Value>-0.80970758841092083</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>-1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>5</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>-1</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>11</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>-1</d5p1:RightIndex>\r\n              <d5p1:Value>1.0798246061959482</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>-1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>6</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>-1</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>12</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>-1</d5p1:RightIndex>\r\n              <d5p1:Value>-0.80970758841092094</d5p1:Value>\r\n            </d5p1:Node>\r\n          </d5p1:Nodes>\r\n          <d5p1:Probabilities xmlns:d6p1=\"http://schemas.microsoft.com/2003/10/Serialization/Arrays\" z:Id=\"31\" z:Size=\"7\">\r\n            <d6p1:ArrayOfdouble z:Id=\"32\" z:Size=\"0\" />\r\n            <d6p1:ArrayOfdouble z:Id=\"33\" z:Size=\"0\" />\r\n            <d6p1:ArrayOfdouble z:Id=\"34\" z:Size=\"0\" />\r\n            <d6p1:ArrayOfdouble z:Id=\"35\" z:Size=\"0\" />\r\n            <d6p1:ArrayOfdouble z:Id=\"36\" z:Size=\"0\" />\r\n            <d6p1:ArrayOfdouble z:Id=\"37\" z:Size=\"0\" />\r\n            <d6p1:ArrayOfdouble z:Id=\"38\" z:Size=\"0\" />\r\n          </d5p1:Probabilities>\r\n          <d5p1:TargetNames xmlns:d6p1=\"http://schemas.microsoft.com/2003/10/Serialization/Arrays\" z:Id=\"39\" z:Size=\"6\">\r\n            <d6p1:double>-0.38249312819055181</d6p1:double>\r\n            <d6p1:double>-0.45542661323256206</d6p1:double>\r\n            <d6p1:double>0.54457338676743794</d6p1:double>\r\n            <d6p1:double>0.61750687180944819</d6p1:double>\r\n            <d6p1:double>0.37687229460654303</d6p1:double>\r\n            <d6p1:double>0.41796300119231988</d6p1:double>\r\n          </d5p1:TargetNames>\r\n          <d5p1:VariableImportance xmlns:d6p1=\"http://schemas.microsoft.com/2003/10/Serialization/Arrays\" z:Id=\"40\" z:Size=\"2\">\r\n            <d6p1:double>0.10080081295831447</d6p1:double>\r\n            <d6p1:double>1.4694059465835321</d6p1:double>\r\n          </d5p1:VariableImportance>\r\n        </d2p1:Tree>\r\n        <d2p1:m_variableImportance xmlns:d5p1=\"http://schemas.microsoft.com/2003/10/Serialization/Arrays\" z:Ref=\"40\" i:nil=\"true\" />\r\n      </d2p1:RegressionDecisionTreeModel>\r\n      <d2p1:RegressionDecisionTreeModel z:Id=\"41\">\r\n        <d2p1:Tree xmlns:d5p1=\"http://schemas.datacontract.org/2004/07/SharpLearning.DecisionTrees.Nodes\" z:Id=\"42\">\r\n          <d5p1:Nodes z:Id=\"43\" z:Size=\"11\">\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>-1</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>2</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>0</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>1</d5p1:RightIndex>\r\n              <d5p1:Value>20</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>0</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>-1</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>4</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>1</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>3</d5p1:RightIndex>\r\n              <d5p1:Value>2.5</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>-1</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>6</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>2</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>5</d5p1:RightIndex>\r\n              <d5p1:Value>4.5</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>-1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>0</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>-1</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>3</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>-1</d5p1:RightIndex>\r\n              <d5p1:Value>0.6333490191620349</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>-1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>1</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>-1</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>4</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>-1</d5p1:RightIndex>\r\n              <d5p1:Value>0.56281717573021062</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>-1</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>8</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>5</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>7</d5p1:RightIndex>\r\n              <d5p1:Value>9.5</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>0</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>-1</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>10</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>6</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>9</d5p1:RightIndex>\r\n              <d5p1:Value>4</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>-1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>2</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>-1</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>7</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>-1</d5p1:RightIndex>\r\n              <d5p1:Value>-0.12306794535228056</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>-1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>3</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>-1</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>8</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>-1</d5p1:RightIndex>\r\n              <d5p1:Value>-0.61933371265172943</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>-1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>4</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>-1</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>9</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>-1</d5p1:RightIndex>\r\n              <d5p1:Value>0.67042394439297548</d5p1:Value>\r\n            </d5p1:Node>\r\n            <d5p1:Node>\r\n              <d5p1:FeatureIndex>-1</d5p1:FeatureIndex>\r\n              <d5p1:LeafProbabilityIndex>5</d5p1:LeafProbabilityIndex>\r\n              <d5p1:LeftIndex>-1</d5p1:LeftIndex>\r\n              <d5p1:NodeIndex>10</d5p1:NodeIndex>\r\n              <d5p1:RightIndex>-1</d5p1:RightIndex>\r\n              <d5p1:Value>-0.62265027399007922</d5p1:Value>\r\n            </d5p1:Node>\r\n          </d5p1:Nodes>\r\n          <d5p1:Probabilities xmlns:d6p1=\"http://schemas.microsoft.com/2003/10/Serialization/Arrays\" z:Id=\"44\" z:Size=\"6\">\r\n            <d6p1:ArrayOfdouble z:Id=\"45\" z:Size=\"0\" />\r\n            <d6p1:ArrayOfdouble z:Id=\"46\" z:Size=\"0\" />\r\n            <d6p1:ArrayOfdouble z:Id=\"47\" z:Size=\"0\" />\r\n            <d6p1:ArrayOfdouble z:Id=\"48\" z:Size=\"0\" />\r\n            <d6p1:ArrayOfdouble z:Id=\"49\" z:Size=\"0\" />\r\n            <d6p1:ArrayOfdouble z:Id=\"50\" z:Size=\"0\" />\r\n          </d5p1:Probabilities>\r\n          <d5p1:TargetNames xmlns:d6p1=\"http://schemas.microsoft.com/2003/10/Serialization/Arrays\" z:Id=\"51\" z:Size=\"15\">\r\n            <d6p1:double>-0.16489814780709319</d6p1:double>\r\n            <d6p1:double>-0.5110439590399255</d6p1:double>\r\n            <d6p1:double>-0.26601195758554835</d6p1:double>\r\n            <d6p1:double>0.4889560409600745</d6p1:double>\r\n            <d6p1:double>-0.22039636061057444</d6p1:double>\r\n            <d6p1:double>0.27726465315934345</d6p1:double>\r\n            <d6p1:double>0.73398804241445159</d6p1:double>\r\n            <d6p1:double>-0.20200351349390658</d6p1:double>\r\n            <d6p1:double>0.21054586827728095</d6p1:double>\r\n            <d6p1:double>0.1622751963635336</d6p1:double>\r\n            <d6p1:double>-0.3755238044493403</d6p1:double>\r\n            <d6p1:double>-0.19698100059301257</d6p1:double>\r\n            <d6p1:double>0.11161204461948115</d6p1:double>\r\n            <d6p1:double>0.30337546093259304</d6p1:double>\r\n            <d6p1:double>0.29750124407070244</d6p1:double>\r\n          </d5p1:TargetNames>\r\n          <d5p1:VariableImportance xmlns:d6p1=\"http://schemas.microsoft.com/2003/10/Serialization/Arrays\" z:Id=\"52\" z:Size=\"2\">\r\n            <d6p1:double>0.015339640988539774</d6p1:double>\r\n            <d6p1:double>0.37234403717308612</d6p1:double>\r\n          </d5p1:VariableImportance>\r\n        </d2p1:Tree>\r\n        <d2p1:m_variableImportance xmlns:d5p1=\"http://schemas.microsoft.com/2003/10/Serialization/Arrays\" z:Ref=\"52\" i:nil=\"true\" />\r\n      </d2p1:RegressionDecisionTreeModel>\r\n    </d2p1:ArrayOfRegressionDecisionTreeModel>\r\n  </m_models>\r\n  <m_predictions xmlns:d2p1=\"http://schemas.microsoft.com/2003/10/Serialization/Arrays\" z:Id=\"53\" z:Size=\"2\">\r\n    <d2p1:double>0</d2p1:double>\r\n    <d2p1:double>0</d2p1:double>\r\n  </m_predictions>\r\n  <m_priorPrababilities xmlns:d2p1=\"http://schemas.microsoft.com/2003/10/Serialization/Arrays\" z:Id=\"54\" z:Size=\"2\">\r\n    <d2p1:double>0.61538461538461542</d2p1:double>\r\n    <d2p1:double>0.38461538461538464</d2p1:double>\r\n  </m_priorPrababilities>\r\n  <m_rawVariableImportance xmlns:d2p1=\"http://schemas.microsoft.com/2003/10/Serialization/Arrays\" z:Id=\"55\" z:Size=\"2\">\r\n    <d2p1:double>0.26264711363264681</d2p1:double>\r\n    <d2p1:double>5.1660752752066941</d2p1:double>\r\n  </m_rawVariableImportance>\r\n  <m_targetNames xmlns:d2p1=\"http://schemas.microsoft.com/2003/10/Serialization/Arrays\" z:Id=\"56\" z:Size=\"2\">\r\n    <d2p1:double>0</d2p1:double>\r\n    <d2p1:double>1</d2p1:double>\r\n  </m_targetNames>\r\n</ClassificationGradientBoostModel>";
    }
}
